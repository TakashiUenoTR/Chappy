# 感情計測技術
| col_1 | 方向<br>（ベクトル） | 表情 | 1 | マーカーレス<br>モーションキャプチャ | Captury（判定はPython） | BlendShape値を取得し機械学習モデルもしくはルールベースで判定。 | マーカーレスモーションキャプチャのカメラで取得可能。（追加のカメラが不要） | BlendShape生波形<br>表情判定結果 | 表情の程度を推定するための学習データの工夫が必要。 | ー |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
|  |  |  | 2 | Webカメラ | MediaPipeで顔を検出<br>Py-Feat、FER、DeepFaceなどの感情推定ライブラリで自作（Python） | 画像から顔を検出し、感情推定ライブラリを用いて7種類の感情（angry、disgust、fear、happy、sad、surprise、neutral）のスコア（確信度）を推定。 | Webカメラ1台で推定可能。 | BlendShape生波形<br>表情判定結果 | 学習データが欧米人メインのため、予測精度は良くても75%程度。顔画像のみから判定するようにモデルが完成されており、バイタルデータと組み合わせた運用が困難。 | ー |
|  |  | 顔向き | 3 | マーカーレス<br>モーションキャプチャ | Captury（判定はPython） | BlendShape値、首の角度を取得し機械学習モデルもしくはルールベースで判定。 | マーカーレスモーションキャプチャのカメラで取得可能。（追加のカメラが不要） | 顔向き判定結果 |  | ー |
|  |  |  | 4 | Webカメラ | MediaPipeで顔を検出<br>OpenCVで首の角度、黒目の向きの判定 | 首の角度、黒目の向きを取得し機械学習モデルもしくはルールベースで判定。 | Webカメラ1台で推定可能。 | 顔向き判定結果 |  | ー |
|  |  | 姿勢変化 | 5 | 体圧センサー | 住友理工　SRソフトビジョン<br>ニッタ　座圧分布測定システム（Conform-Light） | 主に臀部、または身体の一部分にかかる圧力分布を見える化 | デモ機レンタル可能 | 圧力分布のマップ<br>面圧中心点の位置<br>圧力値 | 高額 | ー |
|  |  |  | 6 | 体圧センサー<br>（導電性ポリマーシートなど） | Python<br>Matplotlib<br>OpenCV | 抵抗値の変化をArduinoなどで読み取り、分圧回路で抵抗値を電圧に変換。<br>Python + Matplotlib/OpenCVでヒートマップ表示 |  | 圧力分布のマップ<br>面圧中心点の位置<br>圧力値 |  | ー |
|  |  |  | 7 | Webカメラ | MediaPipeで顔を検出 | 顔領域が画面に占める割合から、顔が近づいた（前傾）、顔が離れた（後傾）を計測し、ピクセル数をリアルタイムに表示 |  | 姿勢変化のピクセル数 |  | ー |
|  |  | 瞬目 | 8 | Webカメラ | MediaPipeで顔を検出<br>OpenCVで瞬目の判定 | 目のアスペクト比（EAR）がある閾値を下回ったときに瞬目を判定 |  | 瞬目のタイミング<br>瞬目頻度（BPM） | 目が細い人 | ー |
|  |  | 発話内容 | 9 | マイク | Teamsの文字起こし、要約機能 | Teams会議を設定し、レコーディング。要約機能でコメント集約。 |  | コメント文字起こし（リアルタイム）<br>コメント要約結果（体験終了後） | 話者分離したい場合は人数分のマイク、Teamsアカウントが必要。 | ー |
|  | 強さ<br>（スカラー） | 心拍 | 10 | Webカメラ（rPPG） | 自作アルゴリズム（Python） |  |  |  | 測定環境の明るさ、前髪、軽帽の影響を受ける可能性あり。カメラを正面に置くので気になるかも。 | 新商品開発部　山中さん、橋本さん |
|  |  |  | 11 | Webカメラ（rPPG） | OpenCV Haar-Cascadeなどのオープンソースを使って自作（Python） | 顔領域の緑成分の時系列変動から心拍信号を抽出、FFTでバンドパスフィルタ→ピーク検出で心拍数・RRIを推定。 | ROIの設定次第で計測結果が大きく変わる。額の中央など安定した場所をROIとし、常に捉えられるカメラ配置にする必要あり。 |  | 同上 | ー |
|  |  |  | 12 | マインドフルネス<br>（呼吸誘導デバイス） | No.10をベースにした自作アルゴリズム（Python） | 心拍間隔長さ（交感神経／副交感神経）、心拍間隔変動（自律神経バランス能力）から、”リラックス”、”集中”、”ストレス”、”無気力”の4象限で推定。 | 100名分の心拍データから4象限のエリア分けをしている。 |  | デバイスを両手で把持する必要があり、UX共創モックでの計測には向いていない。アルゴリズムは活用できる。 | H開　山本さん、中根さん、岡田さん |
|  |  |  | 13 | スマートウォッチ | No.10をベースにした自作アルゴリズム（Python） | スマートウォッチ ⇒ （BLE） ⇒ スマホ ⇒ (Wi-Fi) ⇒ PC の構成でデータ取得が可能。 |  |  |  | 次世代HMIシステム　北川さん、山口さん |
|  |  |  | 14 | Mentoring 2 | 専用アプリ（Mental Battery） | 4つのセンサー（EDA：皮膚電気活動、PPG：脈波、TEMP：体温、加速度/角速度：行動推計）による高精度な生体データを計測。 | デバイスと専用アプリがセット。疲労やストレスの生体情報をリアルタイムかつ高精度に収集。バイタルデータとユーザ入力データを掛け合わせ、同時アルゴリズムによりメンタルスコアを算出。 |  | リングからアプリへの生体データの送信は3分間隔。瞬間的な反応は見られないかも。生データをリアルタイムに送信はできないかも。 | H開　山本さん、中根さん、岡田さん<br>MENTAGRAPH社 |
|  |  |  | 15 | 心拍ベルト<br>（Polar H10など） | 専用アプリ（Polar Flow）<br>もしくは自作アプリ（Python） | Bluetooth Low Energy (BLE)で心拍データを送信、リアルタイム心拍グラフ表示、感情予測まで自作可能。 | 胸部に装着して電極で心電信号を捉える方式（ECG） を採用しており、腕時計の光学式よりノイズが少なく精度が高い。瞬間的な心拍数変動（HRV/リアルタイム取得）が取りやすい。 | 心拍波形<br>心拍数<br>RRI | 薄手の服の上から着用可能だが、電極を濡らす必要があり、装着の負担はあるかも。素肌に装着が正確。 | ー |
|  |  | 呼吸 | 16 | Webカメラ | MediaPipe Poseで胸部座標を取得<br>ROIトラッキング | 胸や肩の動きを解析 |  | 呼吸波形<br>呼吸数（BPM） |  | ー |
|  |  |  | 17 | 呼吸計測デバイス<br>（ZenTracker、呼吸ベルトなど） |  |  |  | 呼吸波形<br>呼吸数（BPM） |  |  |
|  |  | 音声 | 18 | マイク | Librosaなどのオープンソースを使って自作（Python） | マイクから音声を録音し、音声特徴量（MFCC、ピッチ、エネルギー）を抽出、感情を推定。 | ピッチとエネルギーの値から、Happy/Excited、Sad/Tired、Neutralのいずれかを返す簡易ルールベース分類。 | 音声特徴量（MFCC、ピッチ、エネルギー） | 本格的な感情認識には学習済みモデルが必要。現時点での自作アプリは簡易的なルールベースで精度があまり良くない。 | ー |
|  |  |  | 19 |  |  |  |  |  |  |  |
|  |  |  | 20 |  |  |  |  |  |  |  |
